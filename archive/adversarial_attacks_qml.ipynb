{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787515da-18fb-4dad-9c77-7b40d41f832f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcac0192770>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f71711e-1849-49da-baab-60d119d83851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a7e5e2-9b93-4863-aff8-cbf9e948cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = [3, 5, 8, 9]\n",
    "n_px = 8\n",
    "\n",
    "train_size = 10000\n",
    "test_size = 2000\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c76ada56-3532-44ea-bb9f-22f011224d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(digits=[3, 5], n_px=8, train_size=1000, test_size=200):\n",
    "    # Load raw data (uint8 [0-255])\n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True)\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "    # Helper: filter, sample, normalize, resize\n",
    "    def prepare(data, targets, digits, size, n_px):\n",
    "        # Filter by class\n",
    "        mask = torch.zeros_like(targets, dtype=torch.bool)\n",
    "        for d in digits:\n",
    "            mask |= (targets == d)\n",
    "        data_f = data[mask]\n",
    "        targ_f = targets[mask]\n",
    "\n",
    "        # Sample 'size' examples\n",
    "        idx = torch.randperm(len(data_f))[:size]\n",
    "        imgs = data_f[idx].unsqueeze(1).float() / 255.0  # [size,1,28,28]\n",
    "        labs = targ_f[idx]\n",
    "\n",
    "        # Resize to n_px x n_px\n",
    "        imgs_resized = F.interpolate(imgs, size=(n_px, n_px), mode='bilinear', align_corners=False)\n",
    "        # Map labels to 0..len(digits)-1\n",
    "        labs_mapped = torch.tensor([digits.index(int(l)) for l in labs])\n",
    "        return imgs_resized, labs_mapped\n",
    "\n",
    "    x_train, y_train = prepare(mnist_train.data, mnist_train.targets, digits, train_size, n_px)\n",
    "    x_test, y_test   = prepare(mnist_test.data, mnist_test.targets,   digits, test_size,  n_px)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ab3ebf6-6c45-4e6e-ab50-29c05093f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "(x_train, y_train), (x_test, y_test) = get_dataset(digits=digits, n_px=n_px, train_size=train_size, test_size=test_size)\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test,  y_test),  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74ed7c04-6bdf-4735-93cf-480a4cc0f748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Shape : (10000, 8, 8)\n",
      "dType : float32\n",
      "pyType: <class 'pennylane.numpy.tensor.tensor'>\n",
      "Y\n",
      "Shape : (10000,)\n",
      "dType : int64\n",
      "pyType: <class 'pennylane.numpy.tensor.tensor'>\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(np.reshape(x_train, (len(x_train), n_px, n_px)))\n",
    "X_test = np.array(np.reshape(x_test, (len(x_test), n_px, n_px)))\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "\n",
    "print('X')\n",
    "print(f'Shape : {X_train.shape}')\n",
    "print(f'dType : {X_train.dtype}')\n",
    "print(f'pyType: {type(X_train)}')\n",
    "\n",
    "print('Y')\n",
    "print(f'Shape : {Y_train.shape}')\n",
    "print(f'dType : {Y_train.dtype}')\n",
    "print(f'pyType: {type(Y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8516a104-31ee-4c95-9617-d89035aae113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyperparameters ####\n",
    "input_dim = n_px * n_px # 16 X 16 pixels\n",
    "num_classes = len(digits)\n",
    "num_layers = 8\n",
    "num_qubits = 8\n",
    "num_reup = 3\n",
    "\n",
    "class QML_classifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class for creating a quantum machine learning (classification) model based on the StronglyEntanglingLayers template.\n",
    "\n",
    "    Args:\n",
    "        input_dim: the dimension of the input samples\n",
    "        output_dim: the dimension of the output, i.e. the numbers of classes\n",
    "        num_qubits: the number of qubits in the circuit\n",
    "        num_layers: the number of layers within the StronglyEntanglingLayers template\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, num_qubits, num_layers):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1337)  # fixed seed for reproducibility\n",
    "        self.num_qubits = num_qubits\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = qml.device(\"lightning.qubit\", wires=self.num_qubits)\n",
    "        self.weights_shape = qml.StronglyEntanglingLayers.shape(\n",
    "            n_layers=self.num_layers, n_wires=self.num_qubits\n",
    "        )\n",
    "\n",
    "        @qml.qnode(self.device)\n",
    "        def circuit(inputs, weights, bias):\n",
    "            inputs = torch.reshape(inputs, self.weights_shape)\n",
    "            qml.StronglyEntanglingLayers(\n",
    "                weights=weights * inputs + bias, wires=range(self.num_qubits)\n",
    "            )\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.output_dim)]\n",
    "\n",
    "        param_shapes = {\"weights\": self.weights_shape, \"bias\": self.weights_shape}\n",
    "        init_vals = {\n",
    "            \"weights\": 0.1 * torch.rand(self.weights_shape),\n",
    "            \"bias\": 0.1 * torch.rand(self.weights_shape),\n",
    "        }\n",
    "\n",
    "        # initialize the quantum circuit\n",
    "        self.qcircuit = qml.qnn.TorchLayer(\n",
    "            qnode=circuit, weight_shapes=param_shapes, init_method=init_vals\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs_stack = torch.hstack([x] * num_reup)\n",
    "        return self.qcircuit(inputs_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22195e99-8cd0-4229-b3c0-9fec8b8db2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show one image from each class (in the train- and testsets, the images are randomly permuted)\n",
    "x_vis = [(x_train[y_train == i])[0].squeeze(0) for i in range(len(digits))]\n",
    "y_vis = digits\n",
    "\n",
    "# later when we train the model we include the predictions as well, so let's just add the functionality here\n",
    "def visualize_data(x, y, pred=None):\n",
    "    n_img = len(x)\n",
    "    fig, axes = plt.subplots(1, n_img, figsize=(2*n_img, 2))\n",
    "    for i in range(n_img):\n",
    "        axes[i].imshow(x[i], cmap=\"gray\")\n",
    "        if pred is None:\n",
    "            axes[i].set_title(\"Label: {}\".format(y[i]))\n",
    "        else:\n",
    "            axes[i].set_title(\"Label: {}, Pred: {}\".format(y[i], pred[i]))\n",
    "    plt.tight_layout(w_pad=2)\n",
    "    # plt.show()\n",
    "\n",
    "visualize_data(x_vis, y_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff37b1f-0c1d-435c-8165-af36703ce3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop for quantum variational classifier (8 qubits, 8 layers)...\n",
      "Epoch 0/100 | Approx Cost (train): 1.3845421 | Cost (val): 1.3865039 | Approx Acc train: 0.2200000 | Acc val: 0.2250000\n",
      "Epoch 1/100 | Approx Cost (train): 1.3496218 | Cost (val): 1.3650697 | Approx Acc train: 0.3200000 | Acc val: 0.3200000\n",
      "Epoch 2/100 | Approx Cost (train): 1.2688770 | Cost (val): 1.2862529 | Approx Acc train: 0.5000000 | Acc val: 0.4800000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "#### Hyperparameters ####\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "batch_size = 40\n",
    "\n",
    "# we use a subset of the training and validation data for this tutorial to speed up the training\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "\n",
    "feats_train = torch.from_numpy(X_train[:n_train]).reshape(n_train, -1).to(device)\n",
    "feats_test = torch.from_numpy(X_test[:n_test]).reshape(n_test, -1).to(device)\n",
    "labels_train = torch.from_numpy(Y_train[:n_train]).to(device)\n",
    "labels_test = torch.from_numpy(Y_test[:n_test]).to(device)\n",
    "num_train = feats_train.shape[0]\n",
    "\n",
    "# initialize the model, loss function and optimization algorithm (Adam optimizer)\n",
    "qml_model = QML_classifier(input_dim, num_classes, num_qubits, num_layers)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(qml_model.parameters(), lr=learning_rate)\n",
    "num_batches = feats_train.shape[0] // batch_size\n",
    "\n",
    "# set up a measure for performance\n",
    "def accuracy(labels, predictions):\n",
    "    acc = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if torch.argmax(p) == l:\n",
    "            acc += 1\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "# generate randomly permutated batches to speed up training\n",
    "def gen_batches(num_samples, num_batches):\n",
    "    assert num_samples % num_batches == 0\n",
    "    perm_ind = torch.reshape(torch.randperm(num_samples), (num_batches, -1))\n",
    "    return perm_ind\n",
    "\n",
    "\n",
    "# display accuracy and loss after each epoch (to speed up runtime, only do this for first 100 samples)\n",
    "def print_acc(epoch, max_ep=epochs):\n",
    "    predictions_train = [qml_model(f) for f in feats_train[:50]]\n",
    "    predictions_test = [qml_model(f) for f in feats_test]\n",
    "    cost_approx_train = loss(torch.stack(predictions_train), labels_train[:50])\n",
    "    cost_approx_test = loss(torch.stack(predictions_test), labels_test)\n",
    "    acc_approx_train = accuracy(labels_train[:50], predictions_train)\n",
    "    acc_approx_test = accuracy(labels_test, predictions_test)\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{max_ep} | Approx Cost (train): {cost_approx_train:0.7f} | Cost (val): {cost_approx_test:0.7f} |\"\n",
    "        f\" Approx Acc train: {acc_approx_train:0.7f} | Acc val: {acc_approx_test:0.7f}\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Starting training loop for quantum variational classifier ({num_qubits} qubits, {num_layers} layers)...\"\n",
    ")\n",
    "\n",
    "# optimize over model parameters for given number of epochs\n",
    "for ep in range(0, epochs):\n",
    "    batch_ind = gen_batches(num_train, num_batches)\n",
    "    print_acc(epoch=ep)\n",
    "\n",
    "    for it in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "        feats_train_batch = feats_train[batch_ind[it]]\n",
    "        labels_train_batch = labels_train[batch_ind[it]]\n",
    "\n",
    "        outputs = [qml_model(f) for f in feats_train_batch]\n",
    "        batch_loss = loss(torch.stack(outputs), labels_train_batch)\n",
    "        # if REG:\n",
    "        #    loss = loss + lipschitz_regularizer(regularization_rate, model.qcircuit.weights)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print_acc(epochs)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(f\"\\nTime elapsed: {elapsed} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d08274e8-8061-4a4a-bcab-6ed2741511ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QML_classifier Summary:\n",
      "  Input dim:    256\n",
      "  Output dim:   4\n",
      "  Num qubits:   8\n",
      "  Num layers:   32\n",
      "  Num reup:     3\n",
      "\n",
      "Quantum Circuit Layer:\n",
      "  weights    shape: (32, 8, 3) - 768 params\n",
      "  bias       shape: (32, 8, 3) - 768 params\n",
      "\n",
      "Total trainable parameters: 1536\n"
     ]
    }
   ],
   "source": [
    "def print_qml_classifier_summary(model):\n",
    "    print(\"QML_classifier Summary:\")\n",
    "    print(f\"  Input dim:    {input_dim}\")\n",
    "    print(f\"  Output dim:   {model.output_dim}\")\n",
    "    print(f\"  Num qubits:   {model.num_qubits}\")\n",
    "    print(f\"  Num layers:   {model.num_layers}\")\n",
    "    print(f\"  Num reup:     {num_reup}\")\n",
    "    print()\n",
    "\n",
    "    print(\"Quantum Circuit Layer:\")\n",
    "    total_params = 0\n",
    "    for name, param in model.qcircuit.named_parameters():\n",
    "        print(f\"  {name:<10} shape: {tuple(param.shape)} - {param.numel()} params\")\n",
    "        total_params += param.numel()\n",
    "\n",
    "    print(f\"\\nTotal trainable parameters: {total_params}\")\n",
    "\n",
    "# Usage\n",
    "model = QML_classifier(input_dim, num_classes, num_qubits, num_layers)\n",
    "print_qml_classifier_summary(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639010b-73f3-43db-8b6e-527f9b182549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml)",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

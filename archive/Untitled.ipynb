{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e50958fe-79a2-4a1b-a551-0ddd99075349",
   "metadata": {},
   "source": [
    "# MNIST classification classical model (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47338af6-016b-4c69-82df-f94d628653b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 12:02:49.114828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744855369.130792   24469 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744855369.135729   24469 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744855369.148296   24469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744855369.148307   24469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744855369.148309   24469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744855369.148310   24469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch # to use PennyLane TorchLayer class to perform circuit operations and optimisations with PyTorch backend\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.tools import get_dataset, visualise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccec005-8e85-421b-b726-c5211fee107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae2d8f0-9654-4d6b-b151-48bee2468adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_px = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dae8cb4-2589-4240-ab80-934b3ec9e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_px):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(n_px*n_px, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 10),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb88cfe-ce3c-43da-a87f-9549377d99b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=10, bias=True)\n",
      "    (3): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(n_px).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2813c2a0-8a5e-4327-a5b5-e2386bd345d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af5cd14-9e46-4a0c-a7a5-bea3c628379d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Linear.__init__() missing 2 required positional arguments: 'in_features' and 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_px\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mCNN.__init__\u001b[39m\u001b[34m(self, n_px)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.flatten = nn.Flatten()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.convoluitonal_stack = nn.Sequential(\n\u001b[32m      6\u001b[39m     nn.Conv2d(\u001b[32m1\u001b[39m, \u001b[32m32\u001b[39m, kernel_size=\u001b[32m3\u001b[39m),\n\u001b[32m      7\u001b[39m     nn.ReLU(),\n\u001b[32m      8\u001b[39m     nn.Conv2d(\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, kernel_size=\u001b[32m3\u001b[39m),\n\u001b[32m      9\u001b[39m     nn.ReLU(),\n\u001b[32m     10\u001b[39m     nn.MaxPool2d(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m     11\u001b[39m     nn.Dropout(\u001b[32m0.25\u001b[39m),\n\u001b[32m     12\u001b[39m     nn.Flatten(),\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     14\u001b[39m     nn.ReLU(),\n\u001b[32m     15\u001b[39m     nn.Linear(\u001b[32m8\u001b[39m, \u001b[32m10\u001b[39m),\n\u001b[32m     16\u001b[39m     nn.Softmax(),\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Linear.__init__() missing 2 required positional arguments: 'in_features' and 'out_features'"
     ]
    }
   ],
   "source": [
    "model = CNN(n_px).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d8355-b4fb-4110-9e48-ae1af297e221",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2aeb59-24c7-4c4c-b9db-4fef8cc158b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b08d4e-5b7a-47f0-84ba-644b84a900dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        \"\"\"\n",
    "        Define the layers of the convolutional neural network.\n",
    "\n",
    "        Parameters:\n",
    "            in_channels: int\n",
    "                The number of channels in the input image. For MNIST, this is 1 (grayscale images).\n",
    "            num_classes: int\n",
    "                The number of classes we want to predict, in our case 10 (digits 0 to 9).\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel, 8 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer: 2x2 window, stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Second convolutional layer: 8 input channels, 16 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layer: 16*7*7 input features (after two 2x2 poolings), 10 output features (num_classes)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the neural network.\n",
    "\n",
    "        Parameters:\n",
    "            x: torch.Tensor\n",
    "                The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor\n",
    "                The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)            # Apply fully connected layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a681221-fbb9-44ad-a2e5-0f9083108cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dd14a1-f196-47f6-80f6-12e9edccd519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744855370.871236   24469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:02:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = [0,1,2,3]\n",
    "n_px = 16\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_dataset(digits=digits, n_px=n_px)\n",
    "\n",
    "# show one image from each class\n",
    "x_vis = [(x_train[y_train==digit])[np.random.choice(range(10))] for digit in digits] \n",
    "y_vis = range(len(digits))\n",
    "\n",
    "visualise_data(digits, x_vis, y_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b755d0-b480-4f9f-bae1-8770516e5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_px * n_px  # 28x28 pixels (not directly used in CNN)\n",
    "num_classes = len(digits)  # digits 0-9\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10  # Reduced for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46052996-9942-492c-8a64-d3c2829f33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dbfd8c1-51ee-4394-914a-0b1d2e8f711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels=1, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce01aee0-2fe0-4f79-b5e9-182c25aff88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dbeb7ea-a29d-44ac-86a0-6589c390fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 938/938 [00:10<00:00, 88.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:07<00:00, 119.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:07<00:00, 123.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:07<00:00, 122.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:08<00:00, 115.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:08<00:00, 113.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:08<00:00, 115.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:08<00:00, 112.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:08<00:00, 115.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 938/938 [00:07<00:00, 123.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Move data and targets to the device (GPU/CPU)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass: compute the model output\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward pass: compute the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimization step: update the model parameters\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3855cefa-cea0-4b17-bdc6-cc889936cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 59488/60000 with accuracy 99.15%\n",
      "Checking accuracy on test data\n",
      "Got 9869/10000 with accuracy 98.69%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks the accuracy of the model on the given dataset loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader: DataLoader\n",
    "            The DataLoader for the dataset to check accuracy on.\n",
    "        model: nn.Module\n",
    "            The neural network model.\n",
    "    \"\"\"\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)  # Get the index of the max log-probability\n",
    "            num_correct += (predictions == y).sum()  # Count correct predictions\n",
    "            num_samples += predictions.size(0)  # Count total samples\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {accuracy:.2f}%\")\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "# Final accuracy check on training and test sets\n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb5d6e-1e88-46ca-bbe9-4f36457a410f",
   "metadata": {},
   "source": [
    "### PGD attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6080e11c-2f22-434f-a79a-69fa947fe0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple implementation of projected gradient descent (PGD) attack (without randomized starting points — cf. BIM)\n",
    "# for an introduction to PGD, see https://adversarial-ml-tutorial.org/adversarial_examples/#projected-gradient-descent\n",
    "def PGD(model, feats, labels, epsilon=0.1, alpha=0.1, num_iter=10):\n",
    "\n",
    "    # initialize image perturbations with zero\n",
    "    delta = torch.zeros_like(feats, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        feats_adv = feats + delta\n",
    "        outputs = [model(f) for f in feats_adv]\n",
    "\n",
    "        # forward & backward pass through the model, accumulating gradients\n",
    "        l = loss(torch.stack(outputs), labels)\n",
    "        l.backward()\n",
    "\n",
    "        # use gradients with respect to inputs and clip the results to lie within the epsilon boundary\n",
    "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335e377-051f-4cbf-ac47-2309807e4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations = PGD(model=model, feats=x_vis_torch, labels=y_vis_torch, epsilon=0.2) # even smaller values of epsilon do some damage (epsilon > 0.04)\n",
    "perturbed_x = x_vis_torch + perturbations\n",
    "\n",
    "# check model performance\n",
    "adversarial_preds = [model(f) for f in perturbed_x]\n",
    "adversarial_class_output = [torch.argmax(p) for p in adversarial_preds]\n",
    "\n",
    "# visualise_data(digits, perturbed_x.reshape(-1, n_px, n_px), y_vis, adversarial_class_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058852c-abd3-4d37-b28f-a9ead0757d8e",
   "metadata": {},
   "source": [
    "## Tutorial on adversarial robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f46d42-b99a-4e6b-9b17-ed7f0a1d1385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml)",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
